{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install --upgrade pip\n%pip install --disable-pip-version-check \\\n    torch==1.13.1 \\\n    torchdata==0.5.1 --quiet\n\n%pip install \\\n    transformers==4.27.2 \\\n    datasets==2.19.1  --quiet \\\n    fsspec==2022.11.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-24T09:51:33.754011Z","iopub.execute_input":"2025-11-24T09:51:33.754304Z","iopub.status.idle":"2025-11-24T09:51:39.210894Z","shell.execute_reply.started":"2025-11-24T09:51:33.754274Z","shell.execute_reply":"2025-11-24T09:51:39.209476Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.3)\nNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: Ignored the following yanked versions: 0.3.0a0\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchdata==0.5.1 (from versions: 0.3.0a1, 0.3.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torchdata==0.5.1\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: Cannot install datasets==2.19.1 and fsspec==2022.11.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import AutoTokenizer\nfrom transformers import GenerationConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T09:51:39.212584Z","iopub.execute_input":"2025-11-24T09:51:39.212948Z","iopub.status.idle":"2025-11-24T09:51:41.139899Z","shell.execute_reply.started":"2025-11-24T09:51:39.212908Z","shell.execute_reply":"2025-11-24T09:51:41.138884Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"huggingface_dataset_name = \"knkarthick/dialogsum\"\n\ndataset = load_dataset(huggingface_dataset_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T09:51:41.141054Z","iopub.execute_input":"2025-11-24T09:51:41.141611Z","iopub.status.idle":"2025-11-24T09:51:46.771180Z","shell.execute_reply.started":"2025-11-24T09:51:41.141577Z","shell.execute_reply":"2025-11-24T09:51:46.769901Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a458522e688d4ecc8c2eb4a34f1aed1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/11.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb9ca6a279174bb0958d9506139f7112"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/442k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b82a78daeb841bf9c5c4f56c28f508a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64588bdda50b4f489552af749919c9fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cc21c33c8244a8f96412222399d659f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41477f57493b4173b4eebcc7980fd5d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c260b60735d0403280108e1cf21d8375"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"example_indices = [40, 200]\n\ndash_line = '-'.join('' for x in range(100))\n\nfor i, index in enumerate(example_indices):\n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print('INPUT DIALOGUE:')\n    print(dataset['test'][index]['dialogue'])\n    print(dash_line)\n    print('BASELINE HUMAN SUMMARY:')\n    print(dataset['test'][index]['summary'])\n    print(dash_line)\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:23:42.369799Z","iopub.execute_input":"2025-11-24T10:23:42.370756Z","iopub.status.idle":"2025-11-24T10:23:42.378851Z","shell.execute_reply.started":"2025-11-24T10:23:42.370725Z","shell.execute_reply":"2025-11-24T10:23:42.377789Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT DIALOGUE:\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT DIALOGUE:\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model_name='google/flan-t5-base'\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:24:49.988473Z","iopub.execute_input":"2025-11-24T10:24:49.988797Z","iopub.status.idle":"2025-11-24T10:25:04.987743Z","shell.execute_reply.started":"2025-11-24T10:24:49.988776Z","shell.execute_reply":"2025-11-24T10:25:04.986577Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3280bcc2fbf74a6cb31badd2ac174f56"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"428b99ad04ad4fab85735be3af60a0bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"583027a490494518b8cccbbff4197aef"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:25:21.458667Z","iopub.execute_input":"2025-11-24T10:25:21.459003Z","iopub.status.idle":"2025-11-24T10:25:23.395344Z","shell.execute_reply.started":"2025-11-24T10:25:21.458976Z","shell.execute_reply":"2025-11-24T10:25:23.394194Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67779423861248fa84be8ab152dc7b1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d653960693742cbb105e6120ab0d665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de45711807a4562953fec8b94c9fab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1c1c48e2d14c1292cf5bdcd3fddd06"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"sentence = \"What time is it, Tom?\"\n\nsentence_encoded = tokenizer(sentence, return_tensors='pt')\n\nsentence_decoded = tokenizer.decode(\n        sentence_encoded[\"input_ids\"][0], \n        skip_special_tokens=True\n    )\n\nprint('ENCODED SENTENCE:')\nprint(sentence_encoded[\"input_ids\"][0])\nprint('\\nDECODED SENTENCE:')\nprint(sentence_decoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:26:07.988097Z","iopub.execute_input":"2025-11-24T10:26:07.988460Z","iopub.status.idle":"2025-11-24T10:26:29.096254Z","shell.execute_reply.started":"2025-11-24T10:26:07.988435Z","shell.execute_reply":"2025-11-24T10:26:29.095217Z"}},"outputs":[{"name":"stderr","text":"2025-11-24 10:26:09.999169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763979970.302117     153 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763979970.386375     153 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"ENCODED SENTENCE:\ntensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n\nDECODED SENTENCE:\nWhat time is it, Tom?\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n    \n    inputs = tokenizer(dialogue, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{dialogue}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)\n    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:26:56.225170Z","iopub.execute_input":"2025-11-24T10:26:56.225943Z","iopub.status.idle":"2025-11-24T10:26:58.537262Z","shell.execute_reply.started":"2025-11-24T10:26:56.225914Z","shell.execute_reply":"2025-11-24T10:26:58.536369Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - WITHOUT PROMPT ENGINEERING:\nPerson1: It's ten to nine.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n#Person1#: I'm thinking of upgrading my computer.\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nProvide a one-line summary of the following conversation.\n\n{dialogue}\n\nSummary: ?\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:28:51.728919Z","iopub.execute_input":"2025-11-24T10:28:51.729287Z","iopub.status.idle":"2025-11-24T10:28:53.706546Z","shell.execute_reply.started":"2025-11-24T10:28:51.729261Z","shell.execute_reply":"2025-11-24T10:28:53.705579Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nProvide a one-line summary of the following conversation.\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary: ?\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nTom is late for the train.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nProvide a one-line summary of the following conversation.\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary: ?\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1: I'm thinking of upgrading my computer.\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n        \n    prompt = f\"\"\"\nDialogue:\n\n{dialogue}\n\nWhat was going on?\n\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n\n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n    print(dash_line)\n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:31:54.191045Z","iopub.execute_input":"2025-11-24T10:31:54.192501Z","iopub.status.idle":"2025-11-24T10:31:57.854747Z","shell.execute_reply.started":"2025-11-24T10:31:54.192457Z","shell.execute_reply":"2025-11-24T10:31:57.853544Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nDialogue:\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nTom is late for the train.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: You could add a painting program to your software. #Person2#: That would be a bonus. #Person1#: You might also want to upgrade your hardware. #Person1#\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def make_prompt(example_indices_full, example_index_to_summarize):\n    prompt = ''\n    for index in example_indices_full:\n        dialogue = dataset['test'][index]['dialogue']\n        summary = dataset['test'][index]['summary']\n        \n        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n        prompt += f\"\"\"\nDialogue:\n\n{dialogue}\n\nWhat was going on?\n{summary}\n\n\n\"\"\"\n    \n    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n    \n    prompt += f\"\"\"\nDialogue:\n\n{dialogue}\n\nWhat was going on?\n\"\"\"\n        \n    return prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:32:18.296409Z","iopub.execute_input":"2025-11-24T10:32:18.296756Z","iopub.status.idle":"2025-11-24T10:32:18.303080Z","shell.execute_reply.started":"2025-11-24T10:32:18.296732Z","shell.execute_reply":"2025-11-24T10:32:18.301798Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"example_indices_full = [40]\nexample_index_to_summarize = 200\n\none_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(one_shot_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:32:23.867116Z","iopub.execute_input":"2025-11-24T10:32:23.867499Z","iopub.status.idle":"2025-11-24T10:32:23.874941Z","shell.execute_reply.started":"2025-11-24T10:32:23.867473Z","shell.execute_reply":"2025-11-24T10:32:23.873727Z"}},"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nWhat was going on?\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"summary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(one_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ONE SHOT:\\n{output}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:34:15.372391Z","iopub.execute_input":"2025-11-24T10:34:15.372710Z","iopub.status.idle":"2025-11-24T10:34:18.210697Z","shell.execute_reply.started":"2025-11-24T10:34:15.372691Z","shell.execute_reply":"2025-11-24T10:34:18.209400Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ONE SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to add a CD-ROM drive.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"example_indices_full = [40, 80, 120]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:34:46.354715Z","iopub.execute_input":"2025-11-24T10:34:46.355182Z","iopub.status.idle":"2025-11-24T10:34:46.363899Z","shell.execute_reply.started":"2025-11-24T10:34:46.355140Z","shell.execute_reply":"2025-11-24T10:34:46.362437Z"}},"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nWhat was going on?\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n\n\n\nDialogue:\n\n#Person1#: May, do you mind helping me prepare for the picnic?\n#Person2#: Sure. Have you checked the weather report?\n#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n#Person1#: Okay. Please take some fruit salad and crackers for me.\n#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n#Person1#: All set. May, can you help me take all these things to the living room?\n#Person2#: Yes, madam.\n#Person1#: Ask Daniel to give you a hand?\n#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n\nWhat was going on?\nMom asks May to help to prepare for the picnic and May agrees.\n\n\n\nDialogue:\n\n#Person1#: Hello, I bought the pendant in your shop, just before. \n#Person2#: Yes. Thank you very much. \n#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n#Person2#: Oh, is it? \n#Person1#: Would you change it to a new one? \n#Person2#: Yes, certainly. You have the receipt? \n#Person1#: Yes, I do. \n#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n#Person1#: Thank you so much. \n\nWhat was going on?\n#Person1# wants to change the broken pendant in #Person2#'s shop.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"summary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:35:49.747043Z","iopub.execute_input":"2025-11-24T10:35:49.747420Z","iopub.status.idle":"2025-11-24T10:35:53.806028Z","shell.execute_reply.started":"2025-11-24T10:35:49.747388Z","shell.execute_reply":"2025-11-24T10:35:53.804924Z"}},"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# generation_config = GenerationConfig(max_new_tokens=50)\n# generation_config = GenerationConfig(max_new_tokens=20)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\ngeneration_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:37:01.594896Z","iopub.execute_input":"2025-11-24T10:37:01.595297Z","iopub.status.idle":"2025-11-24T10:37:04.334522Z","shell.execute_reply.started":"2025-11-24T10:37:01.595273Z","shell.execute_reply":"2025-11-24T10:37:04.333150Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\nNo new software software is coming out on CDs nowadays.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}